# Prompting the Past

**For several years now, images generated by generative artificial intelligence** systems such as [midjourney](https://www.midjourney.com/home?callbackUrl=%2Fexplore), [DALL·E](https://openai.com/dall-e-2) or [StableDiffusion](https://stability.ai), to give just a few examples, **have become commonplace**. **Like text-generating systems** such as [GPT](https://openai.com/gpt-4), [LLAMA](https://ai.meta.com/llama/) or [BLOOM](https://huggingface.co/bigscience/bloom), **they are based on interaction with users, which notably starts in the writing of prompts. The aim of our current research is to examine the various means at our disposal for transforming not only generated images and texts but also prompts into primary sources for historians.**

---


## digital history and digital memory studies litterature

**Digital history and digital memory studies litterature on AI has expanded since 2022**.

- For instance, Wulf **Kansteiner investigated what a specifically trained generative AI for historians could be** but without really looking at primary sources produced by these systems.

- **The possibilities and risks of AI, particularly generative AI and especially in Holocaust studies, were analysed** in an “open forum” of *Eastern European Holocaust Studies* (@makhortykhOpenForumPossibilities2023). In particular, **the (low) adequacy of the responses of some of the generative AIs to Holocaust research was pointed out** (@makhortykhGenerativeAIContestation2023).

- **Online software can be tested to understand what generative AI systems “know” about history** (@hutchinsonWhatAIsKnow2022).

**Changes -- positive or not -- in the memorialisation processes have also been analysed** (@makhortykhShallAndroidsDream2023), rather from the infrastructure angle. **Most of those articles are also dealing with ethics, privacy and biases** (including biased training dataset). Though research on AI and the past becomes more dense, **as far as I know, there is little research on prompts as a source for history or for the study of collective memory**.

---

## questionning the past...

**GenAI systems have numerous incentives to question the world and prompts are explicit or implicit questions, sometimes about the past**

- Questionning the past is the core activity of historians, their basic epistemological operation in the sense that we ask questions to start the process of elaborating new knowledge about the past.
- The fact that easy to use tools (image or text generative systems) are based on prompts, which are often explicit or implicit questions, should hence get our attention.

- Those systems are incentives to question our world and the world that was, whereas, as “stochastic parrots” (@benderDangersStochasticParrots2021), they are a-epistemological: there is no notion of truth, lie or knowledge in the way those systems are working.

---

## prompts as

- If we consider what those systems are based on (code, training dataset for instance), inputs (prompts) or outputs (images, texts, etc.), then they are generating numerous primary sources -- artefacts that tells us a lot about the societies of the (near) past.
- In my current research, I focus on prompts relating to the past and I consider them
  - as open doors to users' imagination about the past,
  - but also as the result of a user-machine negotiation (when generative systems are not delivering what the user is expecting, the prompt is modified).


---

## Harvesting data

The first methodological barrier to a research project on prompts related to the past is the making of a corpus. There are several ways we could assemble a database of prompts.

- **A first path would be to use dedicated prompt search engines, such as [Lexica](https://lexica.art/)**. Those search engines poses several problems: either they are basic keywords based search engine and collecting prompts would imply a database of past-related keywords, or they are “semantic” (the case of lexica) and becomes hence **black boxes**. A further problem with those search engines is that, in our experience, their developers have not kept a crucial metadata: date and time.
- **A second path would be to directly do what those search engines are doing**: **collecting data on Discord**, an instant messaging and VoIP social platform. Discord has indeed become a keypoint for communities to share their uses of large language models or image-generation systems. Companies such as [midjourney](https://www.midjourney.com/home?callbackUrl=%2Fexplore) have even used [Discord as an interface to their system](https://docs.midjourney.com/docs/midjourney-discord). **Data could then be scrapped from discord public servers -- after consultation of an ethics review panel -- through a bot to respect Discord terms of use**.
- **Third path is to use existing datasets**, including krea open prompts (that I am currently investigating)
- other solutions: setting up a website designed for prompts about the past, or a mix of all those solutions / asking AI firms to work with us, but it's very unlikely they will.

No perfect solutions, probably important to mix all of them.

---

## a balanced corpus?

The hardest part of the constitution of a corpus is nevertheless to create a balanced corpus.

- Databases of prompts lack sociodemographic metadata of authors
  - in other word, we cannot investigate who we are studying
- We need also to define what we mean by ”past”
  - Many prompts are ambiguous: generated images refering to afrofuturism, for insance, are refering to some future and to the past at the same time.

The lack of sociodemographic metadata could then be supplemented by a complementary qualitative approach, based on interviews with users of generative AI systems. Those interviews could also complete the prompts' data by enligthening us on how users are “negotiating“ with the “machine” to get what they expected from it.

---

## Analyzing data

In this analysis, I have collected data from [lexica.art](https://lexica.art)'s search engine. This small corpus (with no personal data, using the lexica API that existed at this time) -- almost a sample corpus -- is made of 1908 prompts (in other experiments, I deal with much more prompts), collected in March 2023 with the keywords 'european union'.

I chose this keyword to see in which ways users are relating to the European Union's and Europe's historical past.

The analysis has been performed with the iramuteq program.

The preliminary results show that references to the past can be of different nature.

- We can find them in the styles users want for an image: 'soviet propaganda' for instance.
- References to the past are mixed with elements of the current or recent news
  - 'marine' for the far-right politician Marine Le Pen in France,
  - 'nigel farage' for the Brexit activist,
  - or references to the Russian agression against Ukraine for instance.

- The notion of 'Europe' is sometimes linked to a precise period of time, usually the Middle Ages ('heraldic') (which is a historical non-sense, unless if you consider far right ideologies).
- Some historical concepts linked to the European history are also quite visible
  - 'empire' for instance,
  - 'war' 
    - our experience shows that there is a general link that is made between history and war in that kind of corpus.


I am today using the krea prompts corpus (10 millions prompts, of course only some small part with historical references), and am experimenting with the more traditional LDA style topic modelling, and to word vectors for now. Using a LLM could of course be a supplementary option. 

---

## Conclusion

- AI-based generative systems are an occasion for historians to investigate new kind of primary sources, including prompts.

Those are presenting some methodological barriers, that can be answered by

1. comprehensive ways to collect data;
2. distant reading of prompts as primary sources.

Nevertheless, distant reading of prompts do not give any insights on how users are negotiating with "the machine" when the generated text or image does not fit their (ideological, cultural, etc) expectations.

We hence suggest that historians should mix quantiative and qualitative methods, including by doing an oral history of the uses of prompts.
